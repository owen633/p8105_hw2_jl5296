---
title: "Homework 2"
author: "Jianyou Liu"
date: "September 30, 2018"
output: github_document
---

```{r setup_load_packages, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```
# Problem 1

### The code chunk below imports the NYC Subway Station data

```{r import_transit_data}
raw_transit_data = read_csv(file = "./hw2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")

raw_transit_data
```
### The code chunk below cleans the NYC Subway Station data

```{r clean1_transit_data}
tidy1_transit_data = 
  janitor::clean_names(raw_transit_data) %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada ) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

tidy1_transit_data
```

The dataset contains **line**, **station names**, **station latitude/longitude**, **routes served**, **whether or not there is an entry**, **whether or not there is a vending machine**, **entrance type**, and **Whether ADA compliant** as its variables.

So far, I cleaned the data by first converting the variables names from uppercase to lowercase. Then, I selected those variables of interest. Finally, I converted the *entry* variable from character to logical. The data is still not tidy right now.

The *dimension* of the resulting data set is `r dim(tidy1_transit_data)`

### The code chunk below further cleans the dataset
```{r clean2_transit_data}
tidy2_transit_data = distinct(tidy1_transit_data, line, station_name, .keep_all = TRUE)

ada_data = filter(tidy2_transit_data, ada == TRUE)

proportion_data = filter(tidy2_transit_data, vending == "NO")

tidy2_transit_data
```
*   The number of distinct stations is equal to `r nrow(tidy2_transit_data)`.
*   `r nrow(ada_data)` stations are ADA compliant.
*   `r table(proportion_data$entry)["TRUE"]/nrow(proportion_data)` of station entrances/exits without vending allow entrance.(Using the dinstict stations dataset)

### The following code chunk reformats data to allow "route number" and "route name" be distinct variables

```{r reformat_data}
reformat_transit_data = 
  gather(tidy2_transit_data, key = route_number, value = route_name, route1:route11) %>% 
  select(line, station_name, route_number, route_name, everything())

reformat_transit_data

A_train_data = filter(reformat_transit_data, route_name == "A")

```
The number of distinct stations that serve train A is `r nrow(A_train_data)`.

Of the stations that serve the A train, `r table(A_train_data$ada)["TRUE"]` are ADA compliant.

# Problem 2

### The following code chunk imports Mr.Trash Wheel dataset and cleans the Mr.Trash Wheel sheet

```{r import_clean_dataset}

wheelsheet_data = read_excel("./hw2_data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 1, range = "A2:N258") %>% 
  janitor::clean_names() %>% 
  rename(weight = weight_tons, volume = volume_cubic_yards) %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))

wheelsheet_data

```
### The following code chunk reads in and cleans data for 2016&2017 precipitation

```{r import_clean_precipitation_data}
precip_2016_data = read_excel("./hw2_data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 4, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  rename(precip_total = total) %>% 
  mutate(year = 2016) %>% 
  select(month, year, precip_total)

precip_2017_data = read_excel("./hw2_data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 3, range = "A2:B10") %>% 
  janitor::clean_names() %>% 
  rename(precip_total = total) %>% 
  mutate(year = 2017) %>% 
  select(month, year, precip_total)

precip_2016_data
precip_2017_data

```
### The following code chunk combines 2016 and 2017 precipitation into a single dataset and converts *month* to a character variable

```{r combine_convert_data}
precip_comb_data = 
  bind_rows(precip_2016_data, precip_2017_data) %>% 
  mutate(month = as.character(month))

precip_comb_data

wheel_2016_data = filter(wheelsheet_data, year == 2016)

```
* The number of observations for the resulting Mr. Trash Wheel dataset is `r nrow(wheelsheet_data)`, and the number of observations for the combined precipitation data of years 2016&2017 is `r nrow(precip_comb_data)`.
* The key variables in the resulting Mr. Trash Wheel dataset are "dumpster number","month","year","date","weight", and "volume". The key variables for the combined precipitation dataset are "month", "year", and "precipitation total".
*   The total precipitation in 2017 is `r sum(precip_2017_data$precip_total)`.
*   The median number of sports balls in a dumpster in 2016 is `r median(wheel_2016_data$sports_balls)`.

# Problem 3

### The following code chunk installs and loads the BRFSS data

```{r install_load_p8105_package, include = FALSE}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)

data("brfss_smart2010")

```
### The following code chunk cleans and reformats the brfss dataset

```{r tidy_brfss_data}
tidy_brfss_data = 
  janitor::clean_names(brfss_smart2010) %>% 
  rename(state = locationabbr, county = locationdesc, resp_id = respid) %>% 
  filter(topic == "Overall Health") %>% 
  select(year:county, response, data_value) %>% 
  spread(response, data_value) %>% 
  janitor::clean_names() %>% 
  select(year, state, county, excellent, very_good, good, fair, poor) %>% 
  arrange(desc(year)) %>% 
  rename(excellent_prop = excellent, very_good_prop = very_good, good_prop = good, fair_prop = fair, poor_prop = poor) %>% 
  mutate(excellent_verygood_prop = excellent_prop + very_good_prop)

tidy_brfss_data

```

